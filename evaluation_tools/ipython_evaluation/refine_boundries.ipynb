{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/huangbo/Desktop/objectdetection/') #Give local path to objectdetection repository\n",
    "import os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import model_from_json\n",
    "from keras.backend import set_image_dim_ordering\n",
    "set_image_dim_ordering('tf')\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_dir = \"/home/huangbo/objectdetection/objectdetection/huangbo_ws/models/06.18_resnet_256/\"\n",
    "model_definition = model_dir + \"model.json\"\n",
    "model_weights = model_dir + \"model.hdf5\"\n",
    "\n",
    "mean = np.array([114.96066323, 116.50405346, 102.74354111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from objectdetection.utils.ml.multi_gpu import load_and_transfer\n",
    "model = load_and_transfer(model_file=model_definition, weights_file=model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml_file = \"/home/huangbo/HuangBo_Projects/data/nordhorn/dataset_500/nordhorn_home.yml\"\n",
    "spec = yaml.load(open(yaml_file, \"rb\").read())\n",
    "file_names = spec[\"validation\"][\"images\"]\n",
    "masks_names = spec[\"validation\"][\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from objectdetection.metrics import semseg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64770141]]\n",
      "0.864098270244\n"
     ]
    }
   ],
   "source": [
    "total_pred = np.int64(0)\n",
    "total_improved = np.int64(0)\n",
    "total_pixels = np.int64(0)\n",
    "\n",
    "ious_cnn = []\n",
    "for i, _ in enumerate(file_names):\n",
    "\n",
    "    image_path = file_names[i]\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR | cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    img = img[0:256, 0:256, :]\n",
    "\n",
    "    img = img - mean\n",
    "    img = img / 255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    masks_path = masks_names[i]\n",
    "    gt = cv2.imread(masks_path, -1)\n",
    "    gt = gt[0:256, 0:256]\n",
    "    cnn_pred = model.predict(img)\n",
    "    cnn_pred = cnn_pred[0].argmax(-1).reshape(256, 256)\n",
    "    \n",
    "#     plt.subplot(1,3,1)\n",
    "#     plt.imshow(img[0, :, :, ::-1])\n",
    "#     plt.subplot(1,3,2)\n",
    "#     plt.imshow(gt)\n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(cnn_pred)\n",
    "    \n",
    "    \n",
    "    iou_cnn = semseg_metric.batch_iou(cnn_pred, gt, 1, 1)\n",
    "    ious_cnn.extend(iou_cnn)\n",
    "   \n",
    "    total_pred += sum(sum(cnn_pred == gt))\n",
    "    total_pixels += 256*256\n",
    "    \n",
    "\n",
    "ious = np.asarray(ious_cnn)\n",
    "intersection, union = np.split(np.sum(ious, axis=0), 2, axis=0)\n",
    "iou_cnn_score = np.true_divide(intersection, union)\n",
    "\n",
    "\n",
    "print iou_cnn_score\n",
    "print np.float128(total_pred) / np.float128(total_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion_matrix:\n",
      "[[  3.98000000e+02   2.99500000e+03   7.26700000e+03   6.47000000e+02\n",
      "    0.00000000e+00   8.29980000e+04   5.50000000e+01   1.74710000e+04\n",
      "    8.57000000e+02   2.08980000e+04   2.06000000e+02]\n",
      " [  4.08000000e+02   7.09486000e+05   7.29760000e+04   1.00000000e+00\n",
      "    0.00000000e+00   1.20073000e+05   5.57000000e+02   1.34020000e+04\n",
      "    1.56620000e+04   3.86800000e+03   8.28100000e+03]\n",
      " [  4.21100000e+03   1.52747000e+05   1.41167500e+06   0.00000000e+00\n",
      "    1.00000000e+00   1.75363000e+05   2.34100000e+03   7.40300000e+04\n",
      "    4.30000000e+02   1.48494000e+05   1.53670000e+04]\n",
      " [  0.00000000e+00   1.54000000e+02   0.00000000e+00   4.55050000e+04\n",
      "    0.00000000e+00   5.97200000e+03   0.00000000e+00   0.00000000e+00\n",
      "    7.90000000e+01   0.00000000e+00   4.16000000e+02]\n",
      " [  0.00000000e+00   7.44500000e+03   2.14700000e+03   0.00000000e+00\n",
      "    1.04000000e+02   3.80000000e+01   0.00000000e+00   1.40000000e+01\n",
      "    0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  6.82000000e+02   6.15840000e+04   7.64740000e+04   2.79800000e+03\n",
      "    0.00000000e+00   2.76805140e+07   1.19640000e+04   1.12232500e+06\n",
      "    1.77120000e+04   4.18825400e+06   9.94500000e+03]\n",
      " [  3.00000000e+00   1.27700000e+03   3.49000000e+03   0.00000000e+00\n",
      "    0.00000000e+00   1.52876000e+05   2.60060000e+04   2.14021000e+05\n",
      "    0.00000000e+00   1.01570000e+04   0.00000000e+00]\n",
      " [  8.50000000e+02   1.26450000e+04   7.42180000e+04   0.00000000e+00\n",
      "    0.00000000e+00   1.11115600e+06   4.67500000e+03   2.24613590e+07\n",
      "    7.42000000e+03   5.68933000e+05   2.05800000e+03]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.60000000e+01\n",
      "    0.00000000e+00   3.78469000e+05   3.20000000e+01   5.31420000e+04\n",
      "    4.58158000e+05   5.88410000e+04   0.00000000e+00]\n",
      " [  1.94200000e+03   1.16370000e+04   3.06010000e+04   0.00000000e+00\n",
      "    0.00000000e+00   5.77738300e+06   1.44900000e+03   7.30851000e+05\n",
      "    1.18070000e+04   5.74305570e+07   1.05900000e+03]\n",
      " [  5.14000000e+02   4.36500000e+03   2.47226000e+05   0.00000000e+00\n",
      "    0.00000000e+00   3.19686000e+05   5.40000000e+02   9.73790000e+04\n",
      "    3.01000000e+02   7.24650000e+05   1.12944000e+05]]\n",
      "the total acc is: 0.86605170921\n",
      "                            f1_score  number_samples  precision    recall\n",
      "background                  0.005574          9008.0   0.002975  0.044183\n",
      "building                    0.743287        964335.0   0.751006  0.735726\n",
      "asphalt/concrete            0.721949       1926074.0   0.711293  0.732929\n",
      "railway                     0.900260         48967.0   0.872981  0.929299\n",
      "cars                        0.021110           105.0   0.010669  0.990476\n",
      "flat vegetation             0.802604      35804528.0   0.834448  0.773101\n",
      "bushes (medium vegetation)  0.114199         47619.0   0.063767  0.546127\n",
      "trees (high vegetation)     0.916280      24783994.0   0.926497  0.906285\n",
      "water                       0.627148        512426.0   0.482954  0.894096\n",
      "fallow land                 0.903338      63154652.0   0.897391  0.909364\n",
      "sand / rock                 0.136251        150276.0   0.074916  0.751577\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "total_pred = np.int64(0)\n",
    "total_improved = np.int64(0)\n",
    "total_pixels = np.int64(0)\n",
    "\n",
    "ious_cnn = []\n",
    "cm = np.zeros(shape=(11,11))\n",
    "for i, _ in enumerate(file_names):\n",
    "\n",
    "    image_path = file_names[i]\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_COLOR | cv2.IMREAD_ANYDEPTH)\n",
    "    \n",
    "    img = img[0:256, 0:256, :]\n",
    "\n",
    "    img = img - mean\n",
    "    img = img / 255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    masks_path = masks_names[i]\n",
    "    gt = cv2.imread(masks_path, -1)\n",
    "    gt = gt[0:256, 0:256]\n",
    "    cnn_pred = model.predict(img)\n",
    "\n",
    "    gt = gt.flatten()\n",
    "    cnn_pred = cnn_pred[0].argmax(-1).reshape(256*256)\n",
    "    cm_new = confusion_matrix(y_true=gt, y_pred=cnn_pred, labels=range(11))\n",
    "    \n",
    "    cm = cm + cm_new\n",
    "\n",
    "print 'The confusion_matrix:'\n",
    "print cm\n",
    "# total accuracy\n",
    "tp = np.trace(cm)\n",
    "tp = float(tp)\n",
    "accuracy = tp / np.sum(cm)\n",
    "print 'the total acc is:', accuracy\n",
    "\n",
    "# recall and precision\n",
    "\n",
    "recall = np.zeros(11, dtype=float)\n",
    "precision = np.zeros(11, dtype=float)\n",
    "f1 = np.zeros(11, dtype=float)\n",
    "nb_samples = np.zeros(11)\n",
    "\n",
    "for i in range(11):\n",
    "    fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "    fn = np.sum(cm[i, :]) - cm[i, i]\n",
    "\n",
    "    if cm[i, i] + fp == 0:\n",
    "        recall[i] = 0\n",
    "    else:\n",
    "        recall[i] = cm[i, i] / (cm[i, i] + fp)\n",
    "\n",
    "    if cm[i, i] + fn == 0:\n",
    "        precision[i] = 0\n",
    "    else:\n",
    "        precision[i] = cm[i, i] / (cm[i, i] + fn)\n",
    "\n",
    "for i in range(11):\n",
    "    nb_samples[i] = np.sum(cm[:, i])\n",
    "    if precision[i] + recall[i] == 0:\n",
    "        f1[i] = 0\n",
    "    else:\n",
    "        f1[i] = 2 * precision[i] * recall[i] / (precision[i] + recall[i])\n",
    "\n",
    "where_are_NaNs = np.isnan(recall)\n",
    "recall[where_are_NaNs] = 0\n",
    "\n",
    "where_are_NaNs = np.isnan(precision)\n",
    "precision[where_are_NaNs] = 0\n",
    "\n",
    "dic_report = {\"recall\": recall,\n",
    "              \"precision\": precision,\n",
    "              \"f1_score\": f1,\n",
    "              \"number_samples\": nb_samples\n",
    "              }\n",
    "\n",
    "labels_index = ['background', 'building', 'asphalt/concrete', 'railway',\n",
    "                  'cars', 'flat vegetation', 'bushes (medium vegetation)',\n",
    "                  'trees (high vegetation)', 'water', 'fallow land', 'sand / rock']\n",
    "\n",
    "\n",
    "print pd.DataFrame(dic_report, index=labels_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 252, 3)\n",
      "(252, 252, 3)\n",
      "(252, 252, 3)\n",
      "(252, 252, 3)\n"
     ]
    }
   ],
   "source": [
    "image_path = file_names[0]\n",
    "img = cv2.imread(image_path, cv2.IMREAD_COLOR | cv2.IMREAD_ANYDEPTH)\n",
    "img1 = img[0:250,0:250,:]\n",
    "img2 = img[250:500,0:250,:]\n",
    "img3 = img[0:250,250:500,:]\n",
    "img4 = img[250:500,250:500,:]\n",
    "\n",
    "img1 = cv2.resize(img1, (252,252), 3)\n",
    "img2 = cv2.resize(img2, (252,252), 3)\n",
    "img3 = cv2.resize(img3, (252,252), 3)\n",
    "img4 = cv2.resize(img4, (252,252), 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    " \n",
    "img1 = img[0:250,0:250,:]\n",
    "img2 = img[250:500,0:250,:]\n",
    "img3 = img[0:250,250:500,:]\n",
    "img4 = img[250:500,250:500,:]\n",
    "\n",
    "img1 = cv2.resize(img1, (252,252), 3)\n",
    "img2 = cv2.resize(img2, (252,252), 3)\n",
    "img3 = cv2.resize(img3, (252,252), 3)\n",
    "img4 = cv2.resize(img4, (252,252), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
